{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "You are tasked to address the task of POS tagging.\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/pos_tagging.png\" alt=\"POS tagging\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# T1 - Corpus\n",
    "\n",
    "Dataset: [Penn TreeBank corpus](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip).\n",
    "\n",
    "Note: **ignoring** the numeric value in the third column, use **only** the words/symbols and their POS label.\n",
    "\n",
    "### Example\n",
    "\n",
    "```Pierre\tNNP\t2\n",
    "Vinken\tNNP\t8\n",
    ",\t,\t2\n",
    "61\tCD\t5\n",
    "years\tNNS\t6\n",
    "old\tJJ\t2\n",
    ",\t,\t2\n",
    "will\tMD\t0\n",
    "join\tVB\t8\n",
    "the\tDT\t11\n",
    "board\tNN\t9\n",
    "as\tIN\t9\n",
    "a\tDT\t15\n",
    "nonexecutive\tJJ\t15\n",
    "director\tNN\t12\n",
    "Nov.\tNNP\t9\n",
    "29\tCD\t16\n",
    ".\t.\t8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file management\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import shutil\n",
    "import urllib\n",
    "import tarfile\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# dataframe management\n",
    "import pandas as pd\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "\n",
    "# for readability\n",
    "from typing import Iterable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Corpus Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "def download_url(download_path: Path, url: str):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=download_path, reporthook=t.update_to)\n",
    "\n",
    "        \n",
    "def download_dataset(download_path: Path, url: str):\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_url(url=url, download_path=download_path)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "def extract_dataset(download_path: Path, extract_path: Path):\n",
    "    print(\"Extracting dataset... (it may take a while...)\")\n",
    "    \n",
    "    # Check if it's a zip file\n",
    "    if download_path.suffix == '.zip':\n",
    "        print(\"Extracting zipfile\")\n",
    "        with zipfile.ZipFile(download_path, 'r') as loaded_zip:\n",
    "            loaded_zip.extractall(extract_path)\n",
    "    \n",
    "    # Check if it's a tar file\n",
    "    elif download_path.suffix in ('.tar', '.gz', '.bz2', '.xz'):\n",
    "        print(\"Extracting tarfile\")\n",
    "        with tarfile.open(download_path) as loaded_tar:\n",
    "            loaded_tar.extractall(extract_path)\n",
    "    \n",
    "    else:\n",
    "        print(\"Unsupported archive format. Please provide a zip or tar file.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory: c:\\Users\\ardiz\\OneDrive\\Desktop\\Projects\\AIML-Research\\ML Foundations\\4 - NLP\\UniBo\\A1-RNN-SequenceLabeling\n",
      "Downloading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dependency_treebank.zip: 0.00B [00:00, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dependency_treebank.zip: 459kB [00:00, 1.49MB/s]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete!\n",
      "Extracting dataset... (it may take a while...)\n",
      "Extracting zipfile\n",
      "Extraction completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds = \"dependency_treebank.zip\"\n",
    "dataset_url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
    "dataset_name = \"dataset/dependency_treebank\"\n",
    "\n",
    "print(f\"Current work directory: {Path.cwd()}\")\n",
    "folder_dataset = Path.cwd().joinpath(\"datasets\")\n",
    "\n",
    "if not folder_dataset.exists():\n",
    "    folder_dataset.mkdir(parents=True)\n",
    "\n",
    "dataset_tar_path = folder_dataset.joinpath(ds)\n",
    "dataset_path = folder_dataset.joinpath(dataset_name)\n",
    "\n",
    "if not dataset_tar_path.exists():\n",
    "    download_dataset(dataset_tar_path, dataset_url)\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    extract_dataset(dataset_tar_path, folder_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the corpus into a pandas.DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Elements: 199\n"
     ]
    }
   ],
   "source": [
    "def count_elements_in_folder(directory_path: Path):\n",
    "    # Get a list of elements in the directory\n",
    "    elements = list(directory_path.iterdir())\n",
    "\n",
    "    # Count the number of elements\n",
    "    num_elements = len(elements)\n",
    "\n",
    "    return num_elements\n",
    "\n",
    "# Example usage:\n",
    "folder_datasetdirectory_path = Path(\"datasets/dependency_treebank\")\n",
    "num_elements = count_elements_in_folder(folder_datasetdirectory_path)\n",
    "\n",
    "print(\"Number of Elements:\", num_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wsj_0001.dp', 'wsj_0002.dp', 'wsj_0003.dp', 'wsj_0004.dp', 'wsj_0005.dp', 'wsj_0006.dp', 'wsj_0007.dp', 'wsj_0008.dp', 'wsj_0009.dp', 'wsj_0010.dp', 'wsj_0011.dp', 'wsj_0012.dp', 'wsj_0013.dp', 'wsj_0014.dp', 'wsj_0015.dp', 'wsj_0016.dp', 'wsj_0017.dp', 'wsj_0018.dp', 'wsj_0019.dp', 'wsj_0020.dp', 'wsj_0021.dp', 'wsj_0022.dp', 'wsj_0023.dp', 'wsj_0024.dp', 'wsj_0025.dp', 'wsj_0026.dp', 'wsj_0027.dp', 'wsj_0028.dp', 'wsj_0029.dp', 'wsj_0030.dp', 'wsj_0031.dp', 'wsj_0032.dp', 'wsj_0033.dp', 'wsj_0034.dp', 'wsj_0035.dp', 'wsj_0036.dp', 'wsj_0037.dp', 'wsj_0038.dp', 'wsj_0039.dp', 'wsj_0040.dp', 'wsj_0041.dp', 'wsj_0042.dp', 'wsj_0043.dp', 'wsj_0044.dp', 'wsj_0045.dp', 'wsj_0046.dp', 'wsj_0047.dp', 'wsj_0048.dp', 'wsj_0049.dp', 'wsj_0050.dp', 'wsj_0051.dp', 'wsj_0052.dp', 'wsj_0053.dp', 'wsj_0054.dp', 'wsj_0055.dp', 'wsj_0056.dp', 'wsj_0057.dp', 'wsj_0058.dp', 'wsj_0059.dp', 'wsj_0060.dp', 'wsj_0061.dp', 'wsj_0062.dp', 'wsj_0063.dp', 'wsj_0064.dp', 'wsj_0065.dp', 'wsj_0066.dp', 'wsj_0067.dp', 'wsj_0068.dp', 'wsj_0069.dp', 'wsj_0070.dp', 'wsj_0071.dp', 'wsj_0072.dp', 'wsj_0073.dp', 'wsj_0074.dp', 'wsj_0075.dp', 'wsj_0076.dp', 'wsj_0077.dp', 'wsj_0078.dp', 'wsj_0079.dp', 'wsj_0080.dp', 'wsj_0081.dp', 'wsj_0082.dp', 'wsj_0083.dp', 'wsj_0084.dp', 'wsj_0085.dp', 'wsj_0086.dp', 'wsj_0087.dp', 'wsj_0088.dp', 'wsj_0089.dp', 'wsj_0090.dp', 'wsj_0091.dp', 'wsj_0092.dp', 'wsj_0093.dp', 'wsj_0094.dp', 'wsj_0095.dp', 'wsj_0096.dp', 'wsj_0097.dp', 'wsj_0098.dp', 'wsj_0099.dp', 'wsj_0100.dp', 'wsj_0101.dp', 'wsj_0102.dp', 'wsj_0103.dp', 'wsj_0104.dp', 'wsj_0105.dp', 'wsj_0106.dp', 'wsj_0107.dp', 'wsj_0108.dp', 'wsj_0109.dp', 'wsj_0110.dp', 'wsj_0111.dp', 'wsj_0112.dp', 'wsj_0113.dp', 'wsj_0114.dp', 'wsj_0115.dp', 'wsj_0116.dp', 'wsj_0117.dp', 'wsj_0118.dp', 'wsj_0119.dp', 'wsj_0120.dp', 'wsj_0121.dp', 'wsj_0122.dp', 'wsj_0123.dp', 'wsj_0124.dp', 'wsj_0125.dp', 'wsj_0126.dp', 'wsj_0127.dp', 'wsj_0128.dp', 'wsj_0129.dp', 'wsj_0130.dp', 'wsj_0131.dp', 'wsj_0132.dp', 'wsj_0133.dp', 'wsj_0134.dp', 'wsj_0135.dp', 'wsj_0136.dp', 'wsj_0137.dp', 'wsj_0138.dp', 'wsj_0139.dp', 'wsj_0140.dp', 'wsj_0141.dp', 'wsj_0142.dp', 'wsj_0143.dp', 'wsj_0144.dp', 'wsj_0145.dp', 'wsj_0146.dp', 'wsj_0147.dp', 'wsj_0148.dp', 'wsj_0149.dp', 'wsj_0150.dp', 'wsj_0151.dp', 'wsj_0152.dp', 'wsj_0153.dp', 'wsj_0154.dp', 'wsj_0155.dp', 'wsj_0156.dp', 'wsj_0157.dp', 'wsj_0158.dp', 'wsj_0159.dp', 'wsj_0160.dp', 'wsj_0161.dp', 'wsj_0162.dp', 'wsj_0163.dp', 'wsj_0164.dp', 'wsj_0165.dp', 'wsj_0166.dp', 'wsj_0167.dp', 'wsj_0168.dp', 'wsj_0169.dp', 'wsj_0170.dp', 'wsj_0171.dp', 'wsj_0172.dp', 'wsj_0173.dp', 'wsj_0174.dp', 'wsj_0175.dp', 'wsj_0176.dp', 'wsj_0177.dp', 'wsj_0178.dp', 'wsj_0179.dp', 'wsj_0180.dp', 'wsj_0181.dp', 'wsj_0182.dp', 'wsj_0183.dp', 'wsj_0184.dp', 'wsj_0185.dp', 'wsj_0186.dp', 'wsj_0187.dp', 'wsj_0188.dp', 'wsj_0189.dp', 'wsj_0190.dp', 'wsj_0191.dp', 'wsj_0192.dp', 'wsj_0193.dp', 'wsj_0194.dp', 'wsj_0195.dp', 'wsj_0196.dp', 'wsj_0197.dp', 'wsj_0198.dp', 'wsj_0199.dp']\n"
     ]
    }
   ],
   "source": [
    "def get_names_of_files_in_folder(directory_path: Path, num_elements: int = 10):\n",
    "    # Get a list of the first 'num_elements' elements in the directory\n",
    "    elements = sorted(directory_path.iterdir())[:num_elements]\n",
    "\n",
    "    # Extract names from the elements\n",
    "    names = [element.name for element in elements]\n",
    "\n",
    "    return names\n",
    "\n",
    "file_names = get_names_of_files_in_folder(folder_datasetdirectory_path, num_elements)\n",
    "\n",
    "print(file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "dataframe_rows = []\n",
    "\n",
    "for file_path in folder_datasetdirectory_path.glob('*.dp'):\n",
    "    phrase = \"\"\n",
    "    tokenized = []\n",
    "    tagged = []\n",
    "    #nouns = []\n",
    "    #verbs = []\n",
    "    #cardinal_digits = []\n",
    "    with file_path.open(mode='r', encoding='utf-8') as text_file:\n",
    "        for row in text_file:\n",
    "            words = re.split(r'\\s+', row)\n",
    "            phrase += words[0] + \" \"\n",
    "            tokenized.append(words[0])\n",
    "            tagged.append((words[0],words[1]))\n",
    "    \n",
    "        dataframe_row = {\n",
    "            \"phrase\": phrase,\n",
    "            \"tokenized\": tokenized,\n",
    "            \"tagged\": tagged\n",
    "        }\n",
    "        dataframe_rows.append(dataframe_row)\n",
    "\n",
    "print(len(dataframe_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_name = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits it in training, validation, and test sets.\n",
    "\n",
    "The corpus contains 200 documents.\n",
    "\n",
    "   * **Train**: Documents 1-100\n",
    "   * **Validation**: Documents 101-150\n",
    "   * **Test**: Documents 151-199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# T2 - Text encoding\n",
    "\n",
    "To train a neural POS tagger, you first need to encode text into numerical format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Embed words using **GloVe embeddings**.\n",
    "* You are **free** to pick any embedding dimension.\n",
    "* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# T3 - Model definition\n",
    "\n",
    "You are now tasked to define your neural POS tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
    "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
    "\n",
    "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
    "* **Model 2**: add an additional Dense layer to the Baseline model.\n",
    "\n",
    "* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n",
    "\n",
    "**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 4 - 1.0 points] Metrics\n",
    "\n",
    "Before training the models, you are tasked to define the evaluation metrics for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Evaluate your models using macro F1-score, compute over **all** tokens.\n",
    "* **Concatenate** all tokens in a data split to compute the F1-score. (**Hint**: accumulate FP, TP, FN, TN iteratively) \n",
    "* **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Note**: What about OOV tokens?\n",
    "   * All the tokens in the **training** set that are not in GloVe **must** be added to the vocabulary.\n",
    "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **special token** (e.g., [UNK]) and a **static** embedding.\n",
    "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### More about OOV\n",
    "\n",
    "For a given token:\n",
    "\n",
    "* **If in train set**: add to vocabulary and assign an embedding (use GloVe if token in GloVe, custom embedding otherwise).\n",
    "* **If in val/test set**: assign special token if not in vocabulary and assign custom embedding. \n",
    "\n",
    "Your vocabulary **should**:\n",
    "\n",
    "* Contain all tokens in train set; or\n",
    "* Union of tokens in train set and in GloVe $\\rightarrow$ we make use of existing knowledge!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Token to embedding mapping\n",
    "\n",
    "You can follow two approaches for encoding tokens in your POS tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Work directly with embeddings\n",
    "\n",
    "- Compute the embedding of each input token\n",
    "- Feed the mini-batches of shape (batch_size, # tokens, embedding_dim) to your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Work with Embedding layer\n",
    "\n",
    "- Encode input tokens to token ids\n",
    "- Define a Embedding layer as the first layer of your model\n",
    "- Compute the embedding matrix of all known tokens (i.e., tokens in your vocabulary)\n",
    "- Initialize the Embedding layer with the computed embedding matrix\n",
    "- You are **free** to set the Embedding layer trainable or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                      output_dim=embedding_dimension,\n",
    "                                      weights=[embedding_matrix],\n",
    "                                      mask_zero=True,                   # automatically masks padding tokens\n",
    "                                      name='encoder_embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Padding\n",
    "\n",
    "Pay attention to padding tokens!\n",
    "\n",
    "Your model **should not** be penalized on those tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### How to?\n",
    "\n",
    "There are two main ways.\n",
    "\n",
    "However, their implementation depends on the neural library you are using.\n",
    "\n",
    "- Embedding layer\n",
    "- Custom loss to compute average cross-entropy on non-padding tokens only\n",
    "\n",
    "**Note**: This is a **recommendation**, but we **do not penalize** for missing workarounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 5 - 1.0 points] Training and Evaluation\n",
    "\n",
    "You are now tasked to train and evaluate the Baseline, Model 1, and Model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Compute metrics on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Pick the **best** performing model according to the observed validation set performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 6 - 1.0 points] Error Analysis\n",
    "\n",
    "You are tasked to evaluate your best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Compare the errors made on the validation and test sets.\n",
    "* Aggregate model errors into categories (if possible) \n",
    "* Comment the about errors and propose possible solutions on how to address them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 7 - 1.0 points] Report\n",
    "\n",
    "Wrap up your experiment in a short report (up to 2 pages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Use the NLP course report template.\n",
    "* Summarize each task in the report following the provided template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Recommendations\n",
    "\n",
    "The report is not a copy-paste of graphs, tables, and command outputs.\n",
    "\n",
    "* Summarize classification performance in Table format.\n",
    "* **Do not** report command outputs or screenshots.\n",
    "* Report learning curves in Figure format.\n",
    "* The error analysis section should summarize your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Submission\n",
    "\n",
    "* **Submit** your report in PDF format.\n",
    "* **Submit** your python notebook.\n",
    "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
    "* You can upload **model weights** in a cloud repository and report the link in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FAQ\n",
    "\n",
    "Please check this frequently asked questions before contacting us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Execution Order\n",
    "\n",
    "You are **free** to address tasks in any order (if multiple orderings are available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Trainable Embeddings\n",
    "\n",
    "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model architecture\n",
    "\n",
    "You **should not** change the architecture of a model (i.e., its layers).\n",
    "\n",
    "However, you are **free** to play with their hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Neural Libraries\n",
    "\n",
    "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Robust Evaluation\n",
    "\n",
    "Each model is trained with at least 3 random seeds.\n",
    "\n",
    "Task 4 requires you to compute the average performance over the 3 seeds and its corresponding standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model Selection for Analysis\n",
    "\n",
    "To carry out the error analysis you are **free** to either\n",
    "\n",
    "* Pick examples or perform comparisons with an individual seed run model (e.g., Baseline seed 1337)\n",
    "* Perform ensembling via, for instance, majority voting to obtain a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Error Analysis\n",
    "\n",
    "Some topics for discussion include:\n",
    "   * Model performance on most/less frequent classes.\n",
    "   * Precision/Recall curves.\n",
    "   * Confusion matrices.\n",
    "   * Specific misclassified samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Punctuation\n",
    "\n",
    "**Do not** remove punctuation from documents since it may be helpful to the model.\n",
    "\n",
    "You should **ignore** it during metrics computation.\n",
    "\n",
    "If you are curious, you can run additional experiments to verify the impact of removing punctuation."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
