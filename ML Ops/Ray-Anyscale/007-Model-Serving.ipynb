{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [7] Model Serving\n",
    "\n",
    "### Batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.data\n",
    "from ray.train.torch import TorchPredictor\n",
    "from ray.data import ActorPoolStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictor\n",
    "run_id = sorted_runs.iloc[0].run_id\n",
    "best_checkpoint = get_best_checkpoint(run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, checkpoint):\n",
    "        self.predictor = TorchPredictor.from_checkpoint(checkpoint)\n",
    "    def __call__(self, batch):\n",
    "        z = self.predictor.predict(batch)[\"predictions\"]\n",
    "        y_pred = np.stack(z).argmax(1)\n",
    "        prediction = decode(y_pred, preprocessor.index_to_class)\n",
    "        return {\"prediction\": prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor()\n",
    "prediction = predictor(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch predict\n",
    "predictions = test_ds.map_batches(\n",
    "    Predictor,\n",
    "    batch_size=128,\n",
    "    compute=ActorPoolStrategy(min_size=1, max_size=2),  # scaling\n",
    "    batch_format=\"pandas\",\n",
    "    fn_constructor_kwargs={\"checkpoint\": best_checkpoint})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample predictions\n",
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from ray import serve\n",
    "import requests\n",
    "from starlette.requests import Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define application\n",
    "app = FastAPI(\n",
    "    title=\"Made With ML\",\n",
    "    description=\"Classify machine learning projects.\",\n",
    "    version=\"0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDeployment:\n",
    "\n",
    "    def __init__(self, run_id):\n",
    "        \"\"\"Initialize the model.\"\"\"\n",
    "        self.run_id = run_id\n",
    "        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)  # so workers have access to model registry\n",
    "        best_checkpoint = get_best_checkpoint(run_id=run_id)\n",
    "        self.predictor = TorchPredictor.from_checkpoint(best_checkpoint)\n",
    "        self.preprocessor = self.predictor.get_preprocessor()\n",
    "\n",
    "    @app.post(\"/predict/\")\n",
    "    async def _predict(self, request: Request):\n",
    "        data = await request.json()\n",
    "        df = pd.DataFrame([{\"title\": data.get(\"title\", \"\"), \"description\": data.get(\"description\", \"\"), \"tag\": \"\"}])\n",
    "        results = predict_with_proba(df=df, predictor=self.predictor)\n",
    "        return {\"results\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(route_prefix=\"/\", num_replicas=\"1\", ray_actor_options={\"num_cpus\": 8, \"num_gpus\": 0})\n",
    "@serve.ingress(app)\n",
    "class ModelDeployment:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run service\n",
    "sorted_runs = mlflow.search_runs(experiment_names=[experiment_name], order_by=[\"metrics.val_loss ASC\"])\n",
    "run_id = sorted_runs.iloc[0].run_id\n",
    "serve.run(ModelDeployment.bind(run_id=run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "title = \"Transfer learning with transformers\"\n",
    "description = \"Using transformers for transfer learning on text classification tasks.\"\n",
    "json_data = json.dumps({\"title\": title, \"description\": description})\n",
    "requests.post(\"http://127.0.0.1:8000/predict/\", data=json_data).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query (noise)\n",
    "title = \" 65n7r5675\"  # random noise\n",
    "json_data = json.dumps({\"title\": title, \"description\": \"\"})\n",
    "requests.post(\"http://127.0.0.1:8000/predict/\", data=json_data).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown\n",
    "serve.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(route_prefix=\"/\", num_replicas=\"1\", ray_actor_options={\"num_cpus\": 8, \"num_gpus\": 0})\n",
    "@serve.ingress(app)\n",
    "class ModelDeploymentRobust:\n",
    "\n",
    "    def __init__(self, run_id, threshold=0.9):\n",
    "        \"\"\"Initialize the model.\"\"\"\n",
    "        self.run_id = run_id\n",
    "        self.threshold = threshold\n",
    "        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)  # so workers have access to model registry\n",
    "        best_checkpoint = get_best_checkpoint(run_id=run_id)\n",
    "        self.predictor = TorchPredictor.from_checkpoint(best_checkpoint)\n",
    "        self.preprocessor = self.predictor.get_preprocessor()\n",
    "\n",
    "    @app.post(\"/predict/\")\n",
    "    async def _predict(self, request: Request):\n",
    "        data = await request.json()\n",
    "        df = pd.DataFrame([{\"title\": data.get(\"title\", \"\"), \"description\": data.get(\"description\", \"\"), \"tag\": \"\"}])\n",
    "        results = predict_with_proba(df=df, predictor=self.predictor)\n",
    "\n",
    "        # Apply custom logic\n",
    "        for i, result in enumerate(results):\n",
    "            pred = result[\"prediction\"]\n",
    "            prob = result[\"probabilities\"]\n",
    "            if prob[pred] < self.threshold:\n",
    "                results[i][\"prediction\"] = \"other\"\n",
    "\n",
    "        return {\"results\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run service\n",
    "serve.run(ModelDeploymentRobust.bind(run_id=run_id, threshold=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query (noise)\n",
    "title = \" 65n7r5675\"  # random noise\n",
    "json_data = json.dumps({\"title\": title, \"description\": \"\"})\n",
    "requests.post(\"http://127.0.0.1:8000/predict/\", data=json_data).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown\n",
    "serve.shutdown()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
